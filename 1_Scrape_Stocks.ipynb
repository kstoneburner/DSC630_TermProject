{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*************************************************************************\n",
    "#//*** Downloads Stock Data and converts the returns to a dataframe,\n",
    "#//*** which saves a compressed CSV file in the stocks folder\n",
    "#//*************************************************************************\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import platform\n",
    "import csv\n",
    "\n",
    "#//*********************************************************************************\n",
    "#//*** Read the API keys from a JSON encoded file\n",
    "#//*** Located in the ignore_folder sub directory\n",
    "#//*** This Folder is added to the .gitignore file and does not show up on Github\n",
    "#//*** This is Authentication Best Practices for Github\n",
    "#//*********************************************************************************\n",
    "f = open(\"./ignore_folder/alpha_vantage_api.json\", \"r\")\n",
    "\n",
    "#//*** Fugley Pythonic type conversion\n",
    "#//*** Loads the file into Dictionary via JSON.loads\n",
    "#//*** Gets the API key value using the 'api' key\n",
    "#//*** prepends apikey= so the resulting value is URL ready :]\n",
    "av_apikey = json.loads(f.read())['apikey']\n",
    "f.close()\n",
    "\n",
    "#//*** Load the Stock Tickers\n",
    "f = open(\".\\\\data\\\\stock_tickers.json\", \"r\")\n",
    "symbols = json.loads(f.read())['symbols']\n",
    "\n",
    "#//*** Just get amc for testing\n",
    "symbols = [ \"amc\" ]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building URL: amc\n",
      "Downloading\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=amc&outputsize=full&apikey=S4DI5C1JRKCLIM74\n",
      "Processing....\n",
      "Building Dataframe\n",
      "Writing dataframe to File: .\\stocks\\amc_daily.csv.zip\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#//*** Alpha Vantage API Docs:\n",
    "#//*** https://www.alphavantage.co/documentation/\n",
    "\n",
    "#//*** Intra day Query\n",
    "#symbol = \"amc\"\n",
    "#url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={symbol}&interval=5min&apikey={av_apikey}'\n",
    "\n",
    "#//*** get prices throughout today\n",
    "#action = \"TIME_SERIES_INTRADAY\"\n",
    "#action = \"TIME_SERIES_DAILY\"\n",
    "#//*** Intraday prices going back two yeares\n",
    "#action = \"TIME_SERIES_INTRADAY_EXTENDED\"\n",
    "#url = f'https://www.alphavantage.co/query?function={action}&symbol={symbol}&interval=60min&slice=year1month1&apikey={av_apikey}'\n",
    "#url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=IBM&interval=60min&slice=year1month3&adjusted=false&apikey={av_apikey}\"\n",
    "\"\"\"\n",
    "\n",
    "#//******************************************************************************\n",
    "#//*** Builds the URL request based on the symbol and type of data requested.\n",
    "#//*** Initially, this does the daily numbers.\n",
    "#//*** Can easily be scaled up to add many different URL request types\n",
    "#//******************************************************************************\n",
    "def build_url(input_action,input_symbol,m=1,y=1):\n",
    "    #//*** Valid Actions:\n",
    "    #//*******  Daily: Gets the historical daily closing price for up to 20 years\n",
    "    \n",
    "    if input_action == 'daily':\n",
    "        action = \"TIME_SERIES_DAILY\"\n",
    "        out = \"\"\n",
    "        out += f'https://www.alphavantage.co/query?'\n",
    "        out += f'function={action}'\n",
    "        out += f'&symbol={symbol}'\n",
    "        out += f'&outputsize=full'\n",
    "        out += f'&apikey={av_apikey}'\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    if input_action == '1min':\n",
    "        action = \"TIME_SERIES_INTRADAY_EXTENDED\"\n",
    "        out = \"\"\n",
    "        out += f'https://www.alphavantage.co/query?'\n",
    "        out += f'function={action}'\n",
    "        out += f'&symbol={symbol}'\n",
    "        out += f'&outputsize=full'\n",
    "        out += f'&slice=year{y}month{m}'\n",
    "        out += f'&interval=1min'\n",
    "        #out += \"datatype=json\"\n",
    "        #out += f'&adjusted=true',\n",
    "        #out += \"&slice=year1month1\",\n",
    "        out += f'&apikey={av_apikey}'\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    if input_action == '60min':\n",
    "        action = \"TIME_SERIES_INTRADAY_EXTENDED\"\n",
    "        out = \"\"\n",
    "        out += f'https://www.alphavantage.co/query?'\n",
    "        out += f'function={action}'\n",
    "        out += f'&symbol={symbol}'\n",
    "        out += f'&outputsize=full'\n",
    "        out += f'&slice=year{y}month{m}'\n",
    "        out += f'&interval=60min'\n",
    "        #out += \"datatype=json\"\n",
    "        #out += f'&adjusted=true',\n",
    "        #out += \"&slice=year1month1\",\n",
    "        out += f'&apikey={av_apikey}'\n",
    "\n",
    "    return out\n",
    "    print(f\"Invalid Action: {input_action}\")\n",
    "    print(f\"No URL Returned, PLease try again\")\n",
    "    return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "action = '1min'\n",
    "action = '60min'\n",
    "action = 'daily'\n",
    "\n",
    "for symbol in symbols:\n",
    "    if (action == '1min') or (action == '60min'):\n",
    "           \n",
    "        #//*** initialize output dataframe\n",
    "        out_df = pd.DataFrame()\n",
    "            \n",
    "        #//*** Loop the year\n",
    "        for year in [1,2]:\n",
    "\n",
    "            #//*** Loop each month\n",
    "            for month in range(1,13):\n",
    "                print(f\"Length out_df: {len(out_df)}\")\n",
    "                print(f\"Building URL: {symbol} - Month {month} Year {year}\")\n",
    "                url = build_url(action,symbol,month,year)\n",
    "\n",
    "                print(\"Downloading\")\n",
    "                print(url)\n",
    "                r = requests.get(url)\n",
    "                print(r.text[:1000])\n",
    "                f = open(\"t.csv\", \"w\")\n",
    "\n",
    "                f.write(r.text)\n",
    "                f.close()\n",
    "\n",
    "                out_df = pd.concat([out_df,pd.read_csv(\"t.csv\")])\n",
    "\n",
    "                print(\"Waiting 20 Seconds\")\n",
    "                time.sleep(20)\n",
    "\n",
    "                    \n",
    "        print(\"df Built\")\n",
    "        print(out_df.head(10))\n",
    "\n",
    "        output_filename = f\"./stocks/{symbol}_{action}.csv.zip\"\n",
    "\n",
    "        #//*** Convert Path to Mac formatting if needed\n",
    "        #if platform.system() == 'Darwin':\n",
    "            #output_filename = output_filename.replace(\"\\\\\",\"/\")\n",
    "\n",
    "        print(f\"Writing dataframe to File: {output_filename}\")\n",
    "        out_df.to_csv(output_filename,compression=\"zip\",index=False)\n",
    "    if action == 'daily':\n",
    "        \n",
    "        #//*** initialize output dataframe\n",
    "        out_df = pd.DataFrame()\n",
    "         \n",
    "        print(f\"Building URL: {symbol}\")\n",
    "        url = build_url(action,symbol)    \n",
    "        \n",
    "        print(\"Downloading\")\n",
    "        print(url)\n",
    "        r = requests.get(url)\n",
    "                    #print(year,month)\n",
    "            #print(\"Waiting 20 Seconds\")\n",
    "            #time.sleep(20)\n",
    "\n",
    "            #//*** Build the Url Request for each symbol\n",
    "    #//*** Verify we built a proper url\n",
    "#    if url != None:\n",
    "        \n",
    "#        print(\"Downloading....\")\n",
    "        #//*** Download the data for each Symbol\n",
    "#        r = requests.get(url)\n",
    "\n",
    "\n",
    "        #//*** Convert raw string to dictionary for processing \n",
    "        data = r.json()\n",
    "\n",
    "        #//*** Get the Key value that contains the list of dates\n",
    "        data_key = list(data.keys())[1]\n",
    "\n",
    "        #//*** Output Dictionary\n",
    "        out_dict = {}\n",
    "        print(\"Processing....\")\n",
    "        #//*** Process Data into the out_dict\n",
    "        for date in data[data_key]:\n",
    "            #//*** Build out_dict (output_dictionary) keys \n",
    "            if len(out_dict.keys()) == 0:\n",
    "                out_dict['date'] = []\n",
    "                out_dict['symbol'] = []\n",
    "\n",
    "                #//*** Get this dictionary for the first row. Use the key values, but strip the first 3 characters which are numeric\n",
    "                for key in data[data_key][date].keys():\n",
    "                    out_dict[key[3:]] = []\n",
    "\n",
    "            #//*** Add Date to out_dict\n",
    "            out_dict['date'].append(date)\n",
    "\n",
    "            #//*** Add Symbol to out_dict\n",
    "            out_dict['symbol'].append(symbol)\n",
    "\n",
    "            #//*** Loop through the daily values and append to the out_dict\n",
    "            for key,value in data[data_key][date].items():\n",
    "\n",
    "                #//*** Trim first 3 characters off key and append to the appropriate dictionary list\n",
    "                out_dict[key[3:]].append(value)\n",
    "\n",
    "        print(\"Building Dataframe\")\n",
    "        out_df = pd.DataFrame()\n",
    "        #//*** Convert the Dictionary to a Dataframe\n",
    "        #//*** Each Key is a column, the data is the list\n",
    "        for key,value in out_dict.items():\n",
    "            out_df[key] = value\n",
    "\n",
    "        #//*** Generic Filename - Placeholder\n",
    "        output_filename = f\".\\\\stocks\\\\{symbol}_need_a_better_name.csv.zip\"\n",
    "        \n",
    "        \n",
    "        #//*** Build filename based on action type\n",
    "        if action == 'daily':\n",
    "            output_filename = f\".\\\\stocks\\\\{symbol}_daily.csv.zip\"\n",
    "        \n",
    "        if action == '1min':\n",
    "            output_filename = f\".\\\\stocks\\\\{symbol}_1min.csv.zip\"\n",
    "\n",
    "        #//*** Convert Path to Mac formatting if needed\n",
    "        if platform.system() == 'Darwin':\n",
    "            output_filename = output_filename.replace(\"\\\\\",\"/\")\n",
    "        \n",
    "        print(f\"Writing dataframe to File: {output_filename}\")\n",
    "        out_df.to_csv(output_filename,compression=\"zip\",index=False)    \n",
    "\n",
    "    #else:\n",
    "    #    print(\"We've got an url problem Skipping\")\n",
    "    \n",
    "    #//*** Wait 20 seconds so we don't hammer the API\n",
    "    #//*** Max is 5 calls / minute & 500 /day\n",
    "    \n",
    "    #print(\"Waiting 20 Seconds\")\n",
    "    #time.sleep(20)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataframe to File: ./stocks/gme_1min.csv.zip\n"
     ]
    }
   ],
   "source": [
    "output_filename = f\"./stocks/{symbol}_{action}.csv.zip\"\n",
    "\n",
    "#//*** Convert Path to Mac formatting if needed\n",
    "#if platform.system() == 'Darwin':\n",
    "    #output_filename = output_filename.replace(\"\\\\\",\"/\")\n",
    "\n",
    "print(f\"Writing dataframe to File: {output_filename}\")\n",
    "out_df.sort_values('time').to_csv(output_filename,compression=\"zip\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245627\n",
      "245627\n"
     ]
    }
   ],
   "source": [
    "tdf = pd.read_csv(output_filename)\n",
    "print(len(tdf['time'].unique()))\n",
    "print(len(tdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-12 20:00:00</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-12 19:53:00</td>\n",
       "      <td>189.44</td>\n",
       "      <td>189.44</td>\n",
       "      <td>189.44</td>\n",
       "      <td>189.44</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-12 19:22:00</td>\n",
       "      <td>189.01</td>\n",
       "      <td>189.01</td>\n",
       "      <td>189.01</td>\n",
       "      <td>189.01</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-12 18:52:00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-12 17:53:00</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>189.50</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>2021-06-14 04:38:00</td>\n",
       "      <td>236.39</td>\n",
       "      <td>236.40</td>\n",
       "      <td>236.39</td>\n",
       "      <td>236.40</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>2021-06-14 04:36:00</td>\n",
       "      <td>236.03</td>\n",
       "      <td>236.03</td>\n",
       "      <td>236.03</td>\n",
       "      <td>236.03</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043</th>\n",
       "      <td>2021-06-14 04:21:00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>237.50</td>\n",
       "      <td>237.50</td>\n",
       "      <td>237.50</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>2021-06-14 04:15:00</td>\n",
       "      <td>235.95</td>\n",
       "      <td>235.95</td>\n",
       "      <td>235.95</td>\n",
       "      <td>235.95</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10045</th>\n",
       "      <td>2021-06-14 04:14:00</td>\n",
       "      <td>235.93</td>\n",
       "      <td>235.93</td>\n",
       "      <td>235.50</td>\n",
       "      <td>235.50</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10046 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time    open    high     low   close  volume\n",
       "0      2021-07-12 20:00:00  189.50  189.50  189.50  189.50     417\n",
       "1      2021-07-12 19:53:00  189.44  189.44  189.44  189.44     118\n",
       "2      2021-07-12 19:22:00  189.01  189.01  189.01  189.01     102\n",
       "3      2021-07-12 18:52:00  189.00  189.00  189.00  189.00     250\n",
       "4      2021-07-12 17:53:00  189.50  189.50  189.50  189.50     163\n",
       "...                    ...     ...     ...     ...     ...     ...\n",
       "10041  2021-06-14 04:38:00  236.39  236.40  236.39  236.40     975\n",
       "10042  2021-06-14 04:36:00  236.03  236.03  236.03  236.03     358\n",
       "10043  2021-06-14 04:21:00  237.50  237.50  237.50  237.50     489\n",
       "10044  2021-06-14 04:15:00  235.95  235.95  235.95  235.95     418\n",
       "10045  2021-06-14 04:14:00  235.93  235.93  235.50  235.50     893\n",
       "\n",
       "[10046 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"t.csv\", \"w\")\n",
    "f.write(r.text)\n",
    "f.close()\n",
    "\n",
    "pd.read_csv(\"t.csv\")\n",
    "\n",
    "\n",
    "#decoded_content = r.decode('utf-8')\n",
    "#cr = csv.reader(r.text.splitlines(), delimiter=',')\n",
    "#cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#//**** INTRA day EXTENDED provides stock data at intervals of 1min, 5min, 15min, 30min, 60min,\\n#//**** Each query provides one month at a time\\n\\nimport csv\\nCSV_URL = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval=15min&slice=year1month1&apikey={av_apikey}'\\n\\nwith requests.Session() as s:\\n    download = s.get(url)\\n    decoded_content = download.content.decode('utf-8')\\n    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\\n    my_list = list(cr)\\n    for row in my_list:\\n        print(row)\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#//**** INTRA day EXTENDED provides stock data at intervals of 1min, 5min, 15min, 30min, 60min,\n",
    "#//**** Each query provides one month at a time\n",
    "\n",
    "import csv\n",
    "CSV_URL = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={symbol}&interval=15min&slice=year1month1&apikey={av_apikey}'\n",
    "\n",
    "with requests.Session() as s:\n",
    "    download = s.get(url)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    my_list = list(cr)\n",
    "    for row in my_list:\n",
    "        print(row)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
