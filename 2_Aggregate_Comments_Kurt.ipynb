{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#//*** Collects pre-sorted Comments\n",
    "#//*** Cleans Comments\n",
    "#//*** Runs tfidf\n",
    "#//*** Perform feature reduction on tfidf using Truncated SVD, preservering around 98% of variance. Cuts the Columns down from 200k+ to 6000\n",
    "#//*** Saves the Truncated SVD for modeling\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import platform\n",
    "\n",
    "import stoneburner\n",
    "#//*** Custom Functions:\n",
    "#//*** mr_clean_text(input_series)\n",
    "#//*** tokenize_series(input_series)\n",
    "#//*** remove_stop_words(input_series)\n",
    "\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#subreddits = [\"wallstreetbets\", \"stocks\", \"wallstreetbetsOGs\", \"spacs\", \"investing\", \"pennystocks\", \"stockmarket\", \"options\", \"robinhoodpennystocks\", \"wallstreetbetsnew\", \"smallstreetbets\"]\n",
    "filepath = \"./data/\"\n",
    "#filename_suffix = \"_comments.csv.zip\"\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-24 09:00:00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.090</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>4.090</td>\n",
       "      <td>406</td>\n",
       "      <td>[index, fund, tracks, performance, stock, mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-24 09:35:00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.150</td>\n",
       "      <td>4.1300</td>\n",
       "      <td>4.150</td>\n",
       "      <td>10116</td>\n",
       "      <td>[combination, options, made, big, some, crmd, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-07-24 09:36:00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.170</td>\n",
       "      <td>4.1385</td>\n",
       "      <td>4.170</td>\n",
       "      <td>16449</td>\n",
       "      <td>[idk, you, know, several, people, hybrids, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-07-24 09:37:00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.180</td>\n",
       "      <td>4.1540</td>\n",
       "      <td>4.175</td>\n",
       "      <td>15605</td>\n",
       "      <td>[thanks, check, out]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-24 09:40:00</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.195</td>\n",
       "      <td>4.1700</td>\n",
       "      <td>4.180</td>\n",
       "      <td>42314</td>\n",
       "      <td>[im, waiting, monday, sell, covered, call, im,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355042</th>\n",
       "      <td>2021-06-30 19:19:00</td>\n",
       "      <td>214.78</td>\n",
       "      <td>214.780</td>\n",
       "      <td>214.7800</td>\n",
       "      <td>214.780</td>\n",
       "      <td>100</td>\n",
       "      <td>[always, possible, like, give, companies, cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355055</th>\n",
       "      <td>2021-06-30 19:40:00</td>\n",
       "      <td>214.80</td>\n",
       "      <td>214.800</td>\n",
       "      <td>214.8000</td>\n",
       "      <td>214.800</td>\n",
       "      <td>176</td>\n",
       "      <td>[business, china, jaded, money, theres, one, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355064</th>\n",
       "      <td>2021-06-30 19:54:00</td>\n",
       "      <td>214.34</td>\n",
       "      <td>214.340</td>\n",
       "      <td>214.3200</td>\n",
       "      <td>214.320</td>\n",
       "      <td>811</td>\n",
       "      <td>[automatically, downvoted, image, alone, then,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355065</th>\n",
       "      <td>2021-06-30 19:55:00</td>\n",
       "      <td>214.15</td>\n",
       "      <td>214.150</td>\n",
       "      <td>214.0000</td>\n",
       "      <td>214.000</td>\n",
       "      <td>1499</td>\n",
       "      <td>[how, get, 12, 000, lost, these, fools, cost, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355068</th>\n",
       "      <td>2021-06-30 19:59:00</td>\n",
       "      <td>214.50</td>\n",
       "      <td>214.500</td>\n",
       "      <td>214.5000</td>\n",
       "      <td>214.500</td>\n",
       "      <td>134</td>\n",
       "      <td>[took, 5, months, squeeze, dividend, announced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    open     high       low    close  volume  \\\n",
       "0        2019-07-24 09:00:00    4.09    4.090    4.0900    4.090     406   \n",
       "11       2019-07-24 09:35:00    4.14    4.150    4.1300    4.150   10116   \n",
       "12       2019-07-24 09:36:00    4.14    4.170    4.1385    4.170   16449   \n",
       "13       2019-07-24 09:37:00    4.17    4.180    4.1540    4.175   15605   \n",
       "14       2019-07-24 09:40:00    4.19    4.195    4.1700    4.180   42314   \n",
       "...                      ...     ...      ...       ...      ...     ...   \n",
       "4355042  2021-06-30 19:19:00  214.78  214.780  214.7800  214.780     100   \n",
       "4355055  2021-06-30 19:40:00  214.80  214.800  214.8000  214.800     176   \n",
       "4355064  2021-06-30 19:54:00  214.34  214.340  214.3200  214.320     811   \n",
       "4355065  2021-06-30 19:55:00  214.15  214.150  214.0000  214.000    1499   \n",
       "4355068  2021-06-30 19:59:00  214.50  214.500  214.5000  214.500     134   \n",
       "\n",
       "                                                     token  \n",
       "0        [index, fund, tracks, performance, stock, mark...  \n",
       "11       [combination, options, made, big, some, crmd, ...  \n",
       "12       [idk, you, know, several, people, hybrids, new...  \n",
       "13                                    [thanks, check, out]  \n",
       "14       [im, waiting, monday, sell, covered, call, im,...  \n",
       "...                                                    ...  \n",
       "4355042  [always, possible, like, give, companies, cred...  \n",
       "4355055  [business, china, jaded, money, theres, one, t...  \n",
       "4355064  [automatically, downvoted, image, alone, then,...  \n",
       "4355065  [how, get, 12, 000, lost, these, fools, cost, ...  \n",
       "4355068  [took, 5, months, squeeze, dividend, announced...  \n",
       "\n",
       "[190326 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Path to file aggregate\n",
    "input_filename = \"./data/processed_reddit_v4_1min.csv.zip\"\n",
    "input_filename = \"./ignore_folder/processed_reddit_v4_1min_amc_stock_comments.pkl\"\n",
    "input_filename = \"./stocks/amc_daily.csv.zip\"\n",
    "output_filename = './ignore_folder/tsvd_model_ready_1min.csv.zip'\n",
    "\n",
    "#raw_df = pd.read_pickle(input_filename)\n",
    "raw_df = pd.read_pickle(input_filename)\n",
    "#//*** How many columns to pre\n",
    "offset_target = \"1\"\n",
    "\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_empty False\n",
      "Text Cleaning Time: 23.369927406311035\n",
      "Tokenize Time: 26.14117121696472\n",
      "Stop Words Time: 20.6454861164093\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#//************************************************\n",
    "#//*** Clean text body\n",
    "#//************************************************\n",
    "\n",
    "raw_df['token'] = stoneburner.remove_stop_words(stoneburner.tokenize_series(stoneburner.mr_clean_text(raw_df['body'],{\"remove_empty\":False})))\n",
    "print(\"Done\")\n",
    "\n",
    "#//*** Detokenize the clean column as tfidf\n",
    "raw_df['tfidf'] = raw_df['token'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tfidf....\n",
      "Built: 4.9\n",
      "  (0, 14299)\t0.03401961698924732\n",
      "  (0, 74899)\t0.04682019536046372\n",
      "  (0, 81673)\t0.030586264755460793\n",
      "  (0, 48755)\t0.015477205176876974\n",
      "  (0, 54192)\t0.02696689468332636\n",
      "  (0, 109155)\t0.024218678637912047\n",
      "  (0, 95210)\t0.017444858699409642\n",
      "  (0, 56220)\t0.027932558423931587\n",
      "  (0, 105071)\t0.09848800926392938\n",
      "  (0, 60648)\t0.06003137748849249\n",
      "  (0, 65489)\t0.02038803993539359\n",
      "  (0, 112084)\t0.05847955838699228\n",
      "  (0, 107166)\t0.03393851063884545\n",
      "  (0, 76114)\t0.030566550978695962\n",
      "  (0, 58136)\t0.02280262763934598\n",
      "  (0, 101644)\t0.013389877265936084\n",
      "  (0, 36280)\t0.027598467281734373\n",
      "  (0, 75327)\t0.029691281040632955\n",
      "  (0, 90284)\t0.06621325995138741\n",
      "  (0, 54337)\t0.020742196951851536\n",
      "  (0, 20812)\t0.03866277717354503\n",
      "  (0, 104988)\t0.07752359839186433\n",
      "  (0, 61244)\t0.025487585687380587\n",
      "  (0, 76213)\t0.02946300083732014\n",
      "  (0, 79548)\t0.03671942130676892\n",
      "  :\t:\n",
      "  (6706, 79279)\t0.03725580570711172\n",
      "  (6706, 101607)\t0.04767484929925102\n",
      "  (6706, 97594)\t0.03956442029169066\n",
      "  (6706, 71133)\t0.04403465577675771\n",
      "  (6706, 38048)\t0.04001365958043071\n",
      "  (6706, 17680)\t0.03779048771594132\n",
      "  (6706, 93008)\t0.050584646193643855\n",
      "  (6706, 113453)\t0.03140550701780037\n",
      "  (6706, 91595)\t0.036832005086660374\n",
      "  (6706, 35715)\t0.0838933392035929\n",
      "  (6706, 70926)\t0.05128443690209715\n",
      "  (6706, 88427)\t0.07596544474809516\n",
      "  (6706, 72071)\t0.03693312738369851\n",
      "  (6706, 109608)\t0.054222483284428566\n",
      "  (6706, 68525)\t0.050455954492025654\n",
      "  (6706, 65122)\t0.06552238199382009\n",
      "  (6706, 67263)\t0.0560464058000737\n",
      "  (6706, 31482)\t0.08724631409179065\n",
      "  (6706, 103122)\t0.06713076094100864\n",
      "  (6706, 41012)\t0.0780029231753176\n",
      "  (6706, 101180)\t0.06034952214308147\n",
      "  (6706, 97121)\t0.06782595872214708\n",
      "  (6706, 112099)\t0.034535436221026325\n",
      "  (6706, 103188)\t0.06745075757660655\n",
      "  (6706, 97469)\t0.03454576100877318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Build tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#loop_list.append(tfidf.fit_transform(input_df['tfidf']))\n",
    "tfidf_matrix = []\n",
    "tfidf_list = []\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "print(\"Starting tfidf....\")\n",
    "start_time = time.time()\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(raw_df['tfidf'])\n",
    "\n",
    "\n",
    "print(f\"Built: {round(time.time()-start_time,2)}\")\n",
    "\n",
    "print(tfidf_matrix)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing uneeded columns...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-29 08:00:00</td>\n",
       "      <td>10.770750</td>\n",
       "      <td>10.866067</td>\n",
       "      <td>10.770750</td>\n",
       "      <td>10.866067</td>\n",
       "      <td>2492</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-29 09:00:00</td>\n",
       "      <td>10.675434</td>\n",
       "      <td>10.923256</td>\n",
       "      <td>10.675434</td>\n",
       "      <td>10.723092</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-29 10:00:00</td>\n",
       "      <td>10.913725</td>\n",
       "      <td>10.923256</td>\n",
       "      <td>10.418080</td>\n",
       "      <td>10.429136</td>\n",
       "      <td>564758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-29 11:00:00</td>\n",
       "      <td>10.422845</td>\n",
       "      <td>10.713560</td>\n",
       "      <td>10.418080</td>\n",
       "      <td>10.694497</td>\n",
       "      <td>247215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-29 12:00:00</td>\n",
       "      <td>10.694497</td>\n",
       "      <td>10.713560</td>\n",
       "      <td>10.580117</td>\n",
       "      <td>10.646839</td>\n",
       "      <td>284815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>2021-07-15 15:00:00</td>\n",
       "      <td>33.938900</td>\n",
       "      <td>35.430000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>35.329100</td>\n",
       "      <td>16629161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>2021-07-15 16:00:00</td>\n",
       "      <td>35.330000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>34.670000</td>\n",
       "      <td>35.991100</td>\n",
       "      <td>19774603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>2021-07-15 17:00:00</td>\n",
       "      <td>35.960000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>35.760000</td>\n",
       "      <td>39.170000</td>\n",
       "      <td>4218169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>2021-07-15 18:00:00</td>\n",
       "      <td>39.170000</td>\n",
       "      <td>39.870000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>3911023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>2021-07-15 19:00:00</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>38.850000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.290000</td>\n",
       "      <td>923939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6868 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time       open       high        low      close  \\\n",
       "0    2019-07-29 08:00:00  10.770750  10.866067  10.770750  10.866067   \n",
       "1    2019-07-29 09:00:00  10.675434  10.923256  10.675434  10.723092   \n",
       "2    2019-07-29 10:00:00  10.913725  10.923256  10.418080  10.429136   \n",
       "3    2019-07-29 11:00:00  10.422845  10.713560  10.418080  10.694497   \n",
       "4    2019-07-29 12:00:00  10.694497  10.713560  10.580117  10.646839   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "6863 2021-07-15 15:00:00  33.938900  35.430000  33.330000  35.329100   \n",
       "6864 2021-07-15 16:00:00  35.330000  36.100000  34.670000  35.991100   \n",
       "6865 2021-07-15 17:00:00  35.960000  39.200000  35.760000  39.170000   \n",
       "6866 2021-07-15 18:00:00  39.170000  39.870000  38.250000  38.750000   \n",
       "6867 2021-07-15 19:00:00  38.750000  38.850000  38.000000  38.290000   \n",
       "\n",
       "        volume  comment_count  \n",
       "0         2492             40  \n",
       "1         2200              0  \n",
       "2       564758              0  \n",
       "3       247215              0  \n",
       "4       284815              0  \n",
       "...        ...            ...  \n",
       "6863  16629161              0  \n",
       "6864  19774603              0  \n",
       "6865   4218169              0  \n",
       "6866   3911023              0  \n",
       "6867    923939              0  \n",
       "\n",
       "[6868 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Remove Uneeded columns\n",
    "\n",
    "#//*** Separate the time into a separate series\n",
    "print(\"Removing uneeded columns...\")\n",
    "#//*** Remove uneeded columns\n",
    "for col in ['body','token','tfidf']:\n",
    "    if col in raw_df.columns:\n",
    "        del raw_df[col]\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Target Offset Columns...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>close_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-29 08:00:00</td>\n",
       "      <td>10.770750</td>\n",
       "      <td>10.866067</td>\n",
       "      <td>10.770750</td>\n",
       "      <td>10.866067</td>\n",
       "      <td>2492</td>\n",
       "      <td>40</td>\n",
       "      <td>10.723092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-29 09:00:00</td>\n",
       "      <td>10.675434</td>\n",
       "      <td>10.923256</td>\n",
       "      <td>10.675434</td>\n",
       "      <td>10.723092</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>10.429136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-29 10:00:00</td>\n",
       "      <td>10.913725</td>\n",
       "      <td>10.923256</td>\n",
       "      <td>10.418080</td>\n",
       "      <td>10.429136</td>\n",
       "      <td>564758</td>\n",
       "      <td>0</td>\n",
       "      <td>10.694497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-29 11:00:00</td>\n",
       "      <td>10.422845</td>\n",
       "      <td>10.713560</td>\n",
       "      <td>10.418080</td>\n",
       "      <td>10.694497</td>\n",
       "      <td>247215</td>\n",
       "      <td>0</td>\n",
       "      <td>10.646839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-29 12:00:00</td>\n",
       "      <td>10.694497</td>\n",
       "      <td>10.713560</td>\n",
       "      <td>10.580117</td>\n",
       "      <td>10.646839</td>\n",
       "      <td>284815</td>\n",
       "      <td>0</td>\n",
       "      <td>10.765984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>2021-07-15 15:00:00</td>\n",
       "      <td>33.938900</td>\n",
       "      <td>35.430000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>35.329100</td>\n",
       "      <td>16629161</td>\n",
       "      <td>0</td>\n",
       "      <td>35.991100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>2021-07-15 16:00:00</td>\n",
       "      <td>35.330000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>34.670000</td>\n",
       "      <td>35.991100</td>\n",
       "      <td>19774603</td>\n",
       "      <td>0</td>\n",
       "      <td>39.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>2021-07-15 17:00:00</td>\n",
       "      <td>35.960000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>35.760000</td>\n",
       "      <td>39.170000</td>\n",
       "      <td>4218169</td>\n",
       "      <td>0</td>\n",
       "      <td>38.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>2021-07-15 18:00:00</td>\n",
       "      <td>39.170000</td>\n",
       "      <td>39.870000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>3911023</td>\n",
       "      <td>0</td>\n",
       "      <td>38.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>2021-07-15 19:00:00</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>38.850000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.290000</td>\n",
       "      <td>923939</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6868 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time       open       high        low      close  \\\n",
       "0    2019-07-29 08:00:00  10.770750  10.866067  10.770750  10.866067   \n",
       "1    2019-07-29 09:00:00  10.675434  10.923256  10.675434  10.723092   \n",
       "2    2019-07-29 10:00:00  10.913725  10.923256  10.418080  10.429136   \n",
       "3    2019-07-29 11:00:00  10.422845  10.713560  10.418080  10.694497   \n",
       "4    2019-07-29 12:00:00  10.694497  10.713560  10.580117  10.646839   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "6863 2021-07-15 15:00:00  33.938900  35.430000  33.330000  35.329100   \n",
       "6864 2021-07-15 16:00:00  35.330000  36.100000  34.670000  35.991100   \n",
       "6865 2021-07-15 17:00:00  35.960000  39.200000  35.760000  39.170000   \n",
       "6866 2021-07-15 18:00:00  39.170000  39.870000  38.250000  38.750000   \n",
       "6867 2021-07-15 19:00:00  38.750000  38.850000  38.000000  38.290000   \n",
       "\n",
       "        volume  comment_count    close_1  \n",
       "0         2492             40  10.723092  \n",
       "1         2200              0  10.429136  \n",
       "2       564758              0  10.694497  \n",
       "3       247215              0  10.646839  \n",
       "4       284815              0  10.765984  \n",
       "...        ...            ...        ...  \n",
       "6863  16629161              0  35.991100  \n",
       "6864  19774603              0  39.170000  \n",
       "6865   4218169              0  38.750000  \n",
       "6866   3911023              0  38.290000  \n",
       "6867    923939              0        NaN  \n",
       "\n",
       "[6868 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#//*** Move this to modeling\n",
    "\n",
    "input_filename = \"./ignore_folder/processed_reddit_v4_60min.pkl.zip\"\n",
    "print(\"Building Target Offset Columns...\")\n",
    "#//*** Build the target variables and intervals of stock prices. This is a single value determined by target)offset\n",
    "\n",
    "#//*** create a list of nan values of x length\n",
    "nan_list = list(np.empty( offset_target )* np.nan )\n",
    "\n",
    "#//*** Create target variable Price which is stocks + x columns in advance\n",
    "#//*** Takes the closing price starting at x and gets the remainder, this generates the offset\n",
    "#//*** nan_list fills the missing x values with nans\n",
    "raw_df[f\"close_{offset_target}\"] = list(raw_df['close'][offset_target:]) + nan_list \n",
    "raw_df    \n",
    "#start_time = time.time()\n",
    "#print(\"Merging...\")\n",
    "##//*** Combine the tfidf sparse array with the stock values\n",
    "#combined_df = pd.concat([raw_df,pd.DataFrame(tfidf_matrix.toarray())], axis=1)\n",
    "#print (f\"Done: {round(time.time()-start_time,2)}s\")\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin PCA \n",
      "0.9878555977289228\n",
      "PCA Done: 1658.65s\n"
     ]
    }
   ],
   "source": [
    "#//*** Build TruncatedSVD\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Begin Truncated SVD \")\n",
    "\n",
    "\n",
    "#//*** Set the number of components to 6000. This is generating 98% variance capture\n",
    "#//*** 60min data set took around 25minutes to build\n",
    "tsvd = TruncatedSVD(6000)\n",
    "tsvd_df = pd.DataFrame(tsvd.fit_transform(tfidf_matrix))\n",
    "print(tsvd.explained_variance_ratio_.sum())\n",
    "\n",
    "print (f\"Truncated SVD Done: {round(time.time()-start_time,2)}s\")\n",
    "output_filename = './ignore_folder/tsvd_model_ready_daily.csv.zip'\n",
    "#//*** Write Truncated SVD to disk\n",
    "tsvd_df.to_csv(output_filename, compression='zip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1303087365492425"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****1k PCA - .45\n",
    "#//****100 PCA = .13\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=6000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "#//*** Write the tsvd object to file, in case it's needed for additional analysis\n",
    "outfile = open('./data/tsvd/truncatedSVD_60min.pkl.zip','wb')\n",
    "pickle.dump(tsvd,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(combined_df)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** set the training columns to use everyting except time\n",
    "predict_col = 'close_1'\n",
    "train_cols = combined_df.columns[1:]\n",
    "train_cols = ['close','volume']\n",
    "\n",
    "x_train = combined_df[train_cols][:1000]\n",
    "y_train = target_df[predict_col][:1000]\n",
    "x_test = combined_df[train_cols][1001:1100]\n",
    "y_test = target_df[predict_col][1001:1100]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "regr = MLPRegressor(max_iter=500).fit(x_train,y_train)\n",
    "#scores = cross_val_score(regr, x_train, y_train, cv=5)\n",
    "#//*** Score the model\n",
    "score = regr.score(x_train, y_train)\n",
    "result = regr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, result)\n",
    "r2 = r2_score(y_test,result)\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Tutorial: https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Begin Train Cols \")\n",
    "train_cols = combined_df.columns[1:]\n",
    "predict_col = 'close_1'\n",
    "print(f\"Begin Slice \")\n",
    "\n",
    "x_train = combined_df[train_cols][:1000]\n",
    "y_train = target_df[predict_col][:1000]\n",
    "x_test = combined_df[train_cols][1001:1013]\n",
    "y_test = target_df[predict_col][1001:1013]\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Begin PCA \")\n",
    "\n",
    "# %%\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "#X = pca.fit_transform( scaler.fit_transform(x_train) ,y_train)\n",
    "x_train = pd.DataFrame(pca.fit_transform( x_train ,y_train))\n",
    "x_test = pd.DataFrame(pca.fit_transform( x_test ,y_train))\n",
    "\n",
    "print(\"Explained Variance Ratio\")\n",
    "for x in range(len(pca.explained_variance_ratio_)):\n",
    "    print(x, pca.explained_variance_ratio_[x])\n",
    "print (f\"PCA Done: {round(time.time()-start_time,2)}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "regr = MLPRegressor(max_iter=1000).fit(x_train,y_train)\n",
    "#scores = cross_val_score(regr, x_train, y_train, cv=5)\n",
    "#//*** Score the model\n",
    "score = regr.score(x_train, y_train)\n",
    "result = regr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, result)\n",
    "r2 = r2_score(y_test,result)\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_x = np.arange(len(y_test))\n",
    "ax.plot(plot_x,y_test )\n",
    "ax.scatter(plot_x,result,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(pca.explained_variance_ratio_)):\n",
    "    print(x, pca.explained_variance_ratio_[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
