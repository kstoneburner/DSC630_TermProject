{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "#from All_data_muduo import df,f1\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "# pd.set_option('display.max_columns',20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at Sparse PCA\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(f2.todense(),index = f1[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Stocks: ./ignore_folder/processed_reddit_v4_60min.pkl.zip\n",
      "Building Time Series\n",
      "Cleaning Columns...\n",
      "Building Target Offset Columns...\n",
      "Check Stock Columns are aligned with offset and time\n",
      "                 time          0      close  volume  comment_count\n",
      "0 2019-07-29 08:00:00  10.723092  10.866067    2492             40\n",
      "1 2019-07-29 09:00:00  10.429136  10.723092    2200              0\n",
      "2 2019-07-29 10:00:00  10.694497  10.429136  564758              0\n",
      "3 2019-07-29 11:00:00  10.646839  10.694497  247215              0\n",
      "4 2019-07-29 12:00:00  10.765984  10.646839  284815              0\n",
      "5 2019-07-29 13:00:00  10.823174  10.765984  342316              0\n",
      "6 2019-07-29 14:00:00  10.842238  10.823174  195521              0\n",
      "7 2019-07-29 15:00:00  10.913725  10.842238  288475              0\n",
      "8 2019-07-29 16:00:00  10.866067  10.913725  626783              0\n",
      "9 2019-07-29 17:00:00  10.723092  10.866067   70681              0\n",
      "                    time        0    close    volume  comment_count\n",
      "6858 2021-07-15 10:00:00  35.7400  36.4199  38351647              0\n",
      "6859 2021-07-15 11:00:00  35.4300  35.7400  46937255              0\n",
      "6860 2021-07-15 12:00:00  35.3371  35.4300  34788196              0\n",
      "6861 2021-07-15 13:00:00  33.9350  35.3371  15245005              0\n",
      "6862 2021-07-15 14:00:00  35.3291  33.9350  15622930              0\n",
      "6863 2021-07-15 15:00:00  35.9911  35.3291  16629161              0\n",
      "6864 2021-07-15 16:00:00  39.1700  35.9911  19774603              0\n",
      "6865 2021-07-15 17:00:00  38.7500  39.1700   4218169              0\n",
      "6866 2021-07-15 18:00:00  38.2900  38.7500   3911023              0\n",
      "6867 2021-07-15 19:00:00      NaN  38.2900    923939              0\n",
      "Building Combined df for training\n",
      "Data is training ready: 29.37s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.866067</td>\n",
       "      <td>2492</td>\n",
       "      <td>40</td>\n",
       "      <td>0.402554</td>\n",
       "      <td>3.667265e-02</td>\n",
       "      <td>-2.067388e-02</td>\n",
       "      <td>-2.935053e-02</td>\n",
       "      <td>1.982483e-02</td>\n",
       "      <td>1.842293e-02</td>\n",
       "      <td>-9.105670e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.574640e-03</td>\n",
       "      <td>-2.147553e-03</td>\n",
       "      <td>4.804881e-04</td>\n",
       "      <td>2.813393e-03</td>\n",
       "      <td>-3.546013e-03</td>\n",
       "      <td>1.252978e-03</td>\n",
       "      <td>-1.564411e-04</td>\n",
       "      <td>1.881156e-03</td>\n",
       "      <td>-4.390987e-03</td>\n",
       "      <td>-5.182442e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.723092</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.178638e-15</td>\n",
       "      <td>-1.039611e-15</td>\n",
       "      <td>5.405201e-15</td>\n",
       "      <td>1.390234e-15</td>\n",
       "      <td>1.561614e-16</td>\n",
       "      <td>-4.274973e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.079595e-17</td>\n",
       "      <td>1.628646e-17</td>\n",
       "      <td>-1.571956e-17</td>\n",
       "      <td>4.342565e-17</td>\n",
       "      <td>6.247059e-17</td>\n",
       "      <td>-2.513909e-17</td>\n",
       "      <td>-1.315520e-16</td>\n",
       "      <td>2.794204e-17</td>\n",
       "      <td>-1.039378e-16</td>\n",
       "      <td>-1.010178e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.429136</td>\n",
       "      <td>564758</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.946596e-16</td>\n",
       "      <td>1.039611e-15</td>\n",
       "      <td>-5.520206e-15</td>\n",
       "      <td>-4.826472e-15</td>\n",
       "      <td>6.662885e-15</td>\n",
       "      <td>-1.502018e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.925873e-18</td>\n",
       "      <td>-1.092926e-17</td>\n",
       "      <td>1.265805e-18</td>\n",
       "      <td>-1.618276e-17</td>\n",
       "      <td>1.421481e-17</td>\n",
       "      <td>2.127558e-17</td>\n",
       "      <td>1.404775e-17</td>\n",
       "      <td>5.760139e-17</td>\n",
       "      <td>8.927591e-17</td>\n",
       "      <td>-1.173689e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.694497</td>\n",
       "      <td>247215</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.039611e-15</td>\n",
       "      <td>-6.900257e-16</td>\n",
       "      <td>-4.196932e-16</td>\n",
       "      <td>4.164303e-16</td>\n",
       "      <td>9.243185e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.046486e-17</td>\n",
       "      <td>3.184681e-17</td>\n",
       "      <td>-2.300131e-17</td>\n",
       "      <td>-9.893506e-19</td>\n",
       "      <td>-8.640583e-17</td>\n",
       "      <td>-9.705423e-17</td>\n",
       "      <td>6.885715e-17</td>\n",
       "      <td>-7.177323e-17</td>\n",
       "      <td>-2.408713e-17</td>\n",
       "      <td>-1.573830e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.646839</td>\n",
       "      <td>284815</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.683245e-17</td>\n",
       "      <td>-2.599027e-16</td>\n",
       "      <td>-4.600171e-16</td>\n",
       "      <td>3.987086e-15</td>\n",
       "      <td>3.747873e-15</td>\n",
       "      <td>-3.697274e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.205619e-17</td>\n",
       "      <td>4.797358e-17</td>\n",
       "      <td>6.272779e-17</td>\n",
       "      <td>-6.131245e-17</td>\n",
       "      <td>-7.046714e-17</td>\n",
       "      <td>5.976357e-17</td>\n",
       "      <td>-6.062463e-17</td>\n",
       "      <td>1.142832e-16</td>\n",
       "      <td>-4.544415e-17</td>\n",
       "      <td>1.093623e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>35.329100</td>\n",
       "      <td>16629161</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>35.991100</td>\n",
       "      <td>19774603</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>39.170000</td>\n",
       "      <td>4218169</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>38.750000</td>\n",
       "      <td>3911023</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>38.290000</td>\n",
       "      <td>923939</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6868 rows Ã— 6003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          close    volume  comment_count         0             1  \\\n",
       "0     10.866067      2492             40  0.402554  3.667265e-02   \n",
       "1     10.723092      2200              0 -0.000000 -1.178638e-15   \n",
       "2     10.429136    564758              0 -0.000000  2.946596e-16   \n",
       "3     10.694497    247215              0 -0.000000  0.000000e+00   \n",
       "4     10.646839    284815              0 -0.000000  3.683245e-17   \n",
       "...         ...       ...            ...       ...           ...   \n",
       "6863  35.329100  16629161              0 -0.000000  0.000000e+00   \n",
       "6864  35.991100  19774603              0 -0.000000  0.000000e+00   \n",
       "6865  39.170000   4218169              0 -0.000000  0.000000e+00   \n",
       "6866  38.750000   3911023              0 -0.000000  0.000000e+00   \n",
       "6867  38.290000    923939              0 -0.000000  0.000000e+00   \n",
       "\n",
       "                 2             3             4             5             6  \\\n",
       "0    -2.067388e-02 -2.935053e-02  1.982483e-02  1.842293e-02 -9.105670e-03   \n",
       "1    -1.039611e-15  5.405201e-15  1.390234e-15  1.561614e-16 -4.274973e-16   \n",
       "2     1.039611e-15 -5.520206e-15 -4.826472e-15  6.662885e-15 -1.502018e-16   \n",
       "3    -1.039611e-15 -6.900257e-16 -4.196932e-16  4.164303e-16  9.243185e-16   \n",
       "4    -2.599027e-16 -4.600171e-16  3.987086e-15  3.747873e-15 -3.697274e-16   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6863  0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6864  0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6865  0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6866  0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6867  0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "\n",
       "      ...          5990          5991          5992          5993  \\\n",
       "0     ...  1.574640e-03 -2.147553e-03  4.804881e-04  2.813393e-03   \n",
       "1     ... -3.079595e-17  1.628646e-17 -1.571956e-17  4.342565e-17   \n",
       "2     ... -5.925873e-18 -1.092926e-17  1.265805e-18 -1.618276e-17   \n",
       "3     ... -4.046486e-17  3.184681e-17 -2.300131e-17 -9.893506e-19   \n",
       "4     ... -1.205619e-17  4.797358e-17  6.272779e-17 -6.131245e-17   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "6863  ...  0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6864  ...  0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6865  ...  0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6866  ...  0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "6867  ...  0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "\n",
       "              5994          5995          5996          5997          5998  \\\n",
       "0    -3.546013e-03  1.252978e-03 -1.564411e-04  1.881156e-03 -4.390987e-03   \n",
       "1     6.247059e-17 -2.513909e-17 -1.315520e-16  2.794204e-17 -1.039378e-16   \n",
       "2     1.421481e-17  2.127558e-17  1.404775e-17  5.760139e-17  8.927591e-17   \n",
       "3    -8.640583e-17 -9.705423e-17  6.885715e-17 -7.177323e-17 -2.408713e-17   \n",
       "4    -7.046714e-17  5.976357e-17 -6.062463e-17  1.142832e-16 -4.544415e-17   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "6863  0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "6864  0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "6865  0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "6866  0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "6867  0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "              5999  \n",
       "0    -5.182442e-03  \n",
       "1    -1.010178e-16  \n",
       "2    -1.173689e-17  \n",
       "3    -1.573830e-17  \n",
       "4     1.093623e-16  \n",
       "...            ...  \n",
       "6863  0.000000e+00  \n",
       "6864  0.000000e+00  \n",
       "6865  0.000000e+00  \n",
       "6866  0.000000e+00  \n",
       "6867  0.000000e+00  \n",
       "\n",
       "[6868 rows x 6003 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_filepath = \"./ignore_folder/tsvd_model_ready_60min.csv.zip\"\n",
    "stock_filepath =  \"./ignore_folder/processed_reddit_v4_60min.pkl.zip\"\n",
    "offset_target = 1\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Reading Stocks: {stock_filepath}\")\n",
    "stock_df = pd.read_pickle(stock_filepath)\n",
    "\n",
    "print(f\"Building Time Series\")\n",
    "#//*** Peel off Time. Used for graphing\n",
    "time_series = stock_df['time']\n",
    "\n",
    "print(f\"Cleaning Columns...\")\n",
    "#//*** Remove uneeded columns\n",
    "for col in ['time','open','high','low','body']:\n",
    "    if col in stock_df.columns:\n",
    "        del stock_df[col]\n",
    "\n",
    "print(\"Building Target Offset Columns...\")\n",
    "#//*** Build the target variables and intervals of stock prices. This is a single value determined by target)offset\n",
    "\n",
    "#//*** create a list of nan values of x length\n",
    "nan_list = list(np.empty( offset_target )* np.nan )\n",
    "\n",
    "#//*** Create target variable Price which is stocks + x columns in advance\n",
    "#//*** Takes the closing price starting at x and gets the remainder, this generates the offset\n",
    "#//*** nan_list fills the missing x values with nans\n",
    "target = list(stock_df['close'][offset_target:]) + nan_list \n",
    "\n",
    "print(f\"Check Stock Columns are aligned with offset and time\")\n",
    "#//*** Temporarily merge stock_df, time_series, and target series. \n",
    "#//*** Make sure everything is aligning correctly.\n",
    "temp_df = pd.concat([pd.DataFrame(time_series),pd.DataFrame(target),stock_df],axis=1)\n",
    "print(temp_df.head(10))\n",
    "print(temp_df.tail(10))\n",
    "\n",
    "print(f\"Building Combined df for training\")\n",
    "df = pd.concat([stock_df,pd.read_csv(training_filepath)],axis=1)\n",
    "\n",
    "#//*** Delete unused variables to free up memory\n",
    "try:\n",
    "    \n",
    "    del temp_df\n",
    "    del stock_df\n",
    "except:\n",
    "    print()\n",
    "print (f\"Data is training ready: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = df[:1000]\n",
    "y_train = target[:1000]\n",
    "x_test = df[1001:1100]\n",
    "y_test = target[1001:1100]\n",
    "plot_x = time_series[1001:1100]\n",
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "regr = MLPRegressor(max_iter=500).fit(x_train,y_train)\n",
    "#scores = cross_val_score(regr, x_train, y_train, cv=5)\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "#//*** Score the model\n",
    "score = regr.score(x_train, y_train)\n",
    "result = regr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, result)\n",
    "\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "print(score)\n",
    "print(rmse)\n",
    "#print(result)\n",
    "\n",
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(plot_x,y_test )\n",
    "ax.scatter(plot_x,result,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing\n",
      "Complete: 397.18\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f2fcfcf87730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# %%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0merr2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr_predict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mmean_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv(\"~/Documents/GitHub/Project/ignore_folder/1min_ml_1000_pca\",compression=\"zip\")\n",
    "\n",
    "#%%\n",
    "X,y = df[:1000], target[:1000]\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "# %%\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes = 5000, max_iter=50000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, shuffle=False)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#%%\n",
    "regr.score(X_test, y_test)\n",
    "\n",
    "#%%\n",
    "#regr.c\n",
    "# %%\n",
    "#score = cross_val_score(regr, X,y,n_jobs=-1,cv=3)\n",
    "# %%\n",
    "regr_predict = regr.predict(X_test)\n",
    "\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "# %%\n",
    "import numpy as np\n",
    "err2= np.sqrt(abs((np.square(regr_predict) - np.square(y_test)))).sum()\n",
    "mean_err = err2/len(y_test)\n",
    "rmse = np.sqrt(mean_err)\n",
    "\n",
    "##%%\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(range(len(regr_predict[0:200])), regr_predict[0:200])\n",
    "#plt.plot(range(len(y_test[0:200])), y_test[0:200])\n",
    "\n",
    "# plot(x= range(len(y_test)), y=y_test)\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1db9d414a94c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# %%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0merr2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr_predict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mmean_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#err2= np.sqrt(abs((np.square(regr_predict) - np.square(pd.Series(y_test))))).sum()\n",
    "#mean_err = err2/len(y_test)\n",
    "rmse = np.sqrt(mean_err)\n",
    "\n",
    "#score = cross_val_score(regr, X,y,n_jobs=-1,cv=3)\n",
    "# %%\n",
    "regr_predict = regr.predict(X_test)\n",
    "\n",
    "#print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "# %%\n",
    "import numpy as np\n",
    "err2= np.sqrt(abs((np.square(regr_predict) - np.square(y_test.values)))).sum()\n",
    "mean_err = err2/len(y_test)\n",
    "rmse = np.sqrt(mean_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(range(len(regr_predict)),y_test )\n",
    "ax.scatter(range(len(regr_predict)),regr_predict,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#//*** Define the Prediction (Target) Column\n",
    "predict_col = 'close_5'\n",
    "\n",
    "#//*** Build a list of the PCA Columns\n",
    "pca_cols = list(df.columns[17:])\n",
    "stock_cols = ['close','volume']\n",
    "train_cols = stock_cols + pca_cols\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_x = np.arange(len(y_test))\n",
    "ax.plot(plot_x,y_test )\n",
    "ax.scatter(plot_x,result,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['target','rmse','r2','start','end','predict_range','model_time','actual','predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Normalization: https://stackoverflow.com/questions/62131266/mlpregressor-working-but-results-dont-make-any-sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Pick start and end iLoc for training\n",
    "predictions_in_advance = 5000\n",
    "training_range = 5000\n",
    "\n",
    "#//*** Loop through each of the target variables\n",
    "for tgt_col in df.columns[7:17]:\n",
    "    \n",
    "    #//*** Model progressive slices of the data\n",
    "    for x in range(10,60):\n",
    "        \n",
    "        #//*** Training start is counter * the training range\n",
    "        train_start = x * training_range\n",
    "\n",
    "        #//*** End Training at start + range\n",
    "        train_end   = train_start + training_range\n",
    "        \n",
    "        #//*** Target Column\n",
    "        predict_col = tgt_col\n",
    "\n",
    "        #//*** Build Training set from start iloc to end iloc\n",
    "        x_train = df[train_cols][train_start:train_end]\n",
    "        y_train = df[predict_col][train_start:train_end]\n",
    "\n",
    "        #//*** Build Test set from Training End + predictions_in_advace\n",
    "        x_test = df[train_cols][train_end:train_end + predictions_in_advance]\n",
    "        y_test = df[predict_col][train_end:train_end + predictions_in_advance]\n",
    "\n",
    "        #//*** Scale the training data\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train_norm = scaler.fit_transform(x_train)\n",
    "        x_test_norm = scaler.fit_transform(x_test)\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"Regressing\")\n",
    "        \n",
    "        #//*** Fit the regressor\n",
    "        regr = MLPRegressor(max_iter=5000).fit(x_train_norm,y_train)\n",
    "\n",
    "        #score = regr.score(x_train, y_train)\n",
    "        \n",
    "        #//*** Generate Predictions\n",
    "        result = regr.predict(x_test_norm)\n",
    "\n",
    "        #//*** Mean Squared error\n",
    "        mse = mean_squared_error(y_test, result)\n",
    "\n",
    "        #//*** These are values to be added to results_df\n",
    "        target = predict_col\n",
    "        \n",
    "        #//*** Root Mean squared Error\n",
    "        rmse = sqrt(mse)\n",
    "        #//*** r2 score for model evaluation\n",
    "        r2 = r2_score(y_test,result)\n",
    "        start = train_start\n",
    "        end = train_end\n",
    "        predict_range = training_range\n",
    "        model_time = round(time.time()-start_time,2)\n",
    "        print(f\"Complete: {model_time}s\" )\n",
    "        actual = y_test\n",
    "        predict = result\n",
    "\n",
    "        #//*** Update Results_df\n",
    "        results_df.loc[len(results_df)] = [target,rmse,r2,start,end,predict_range,model_time,actual,predict]\n",
    "\n",
    "        #//*** PLot Results\n",
    "        fig,ax = plt.subplots()\n",
    "        plot_x = np.arange(len(y_test))\n",
    "        ax.plot(plot_x,y_test )\n",
    "        ax.scatter(plot_x,result,color='red' )\n",
    "\n",
    "        title= \"\"\n",
    "        title+=f\"Training Range: {train_start} - {train_end}\\n\"\n",
    "        title+=f\"Prediction Range: {train_end} - {train_end + predictions_in_advance}\\n\"\n",
    "        title+=f\"Target: {predict_col} rmse:[{round(rmse,4)}] [Model score: ({round(score,4)})]\\nr2: ({r2})\"\n",
    "        plt.title(title)    \n",
    "        plt.show()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle('./results/results_amc_1min_MLPRegressor_v1.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
