{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#//*** Collects pre-sorted Comments\n",
    "#//*** Cleans Comments\n",
    "#//*** Runs tfidf\n",
    "#//*** Perform feature reduction on tfidf using Truncated SVD, preservering around 98% of variance. Cuts the Columns down from 200k+ to 6000\n",
    "#//*** Saves the Truncated SVD for modeling\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import platform\n",
    "\n",
    "import stoneburner\n",
    "#//*** Custom Functions:\n",
    "#//*** mr_clean_text(input_series)\n",
    "#//*** tokenize_series(input_series)\n",
    "#//*** remove_stop_words(input_series)\n",
    "\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#subreddits = [\"wallstreetbets\", \"stocks\", \"wallstreetbetsOGs\", \"spacs\", \"investing\", \"pennystocks\", \"stockmarket\", \"options\", \"robinhoodpennystocks\", \"wallstreetbetsnew\", \"smallstreetbets\"]\n",
    "filepath = \"./data/\"\n",
    "#filename_suffix = \"_comments.csv.zip\"\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-24 09:00:00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.090</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>4.090</td>\n",
       "      <td>406</td>\n",
       "      <td>[index, fund, tracks, performance, stock, mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-24 09:35:00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.150</td>\n",
       "      <td>4.1300</td>\n",
       "      <td>4.150</td>\n",
       "      <td>10116</td>\n",
       "      <td>[combination, options, made, big, some, crmd, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-07-24 09:36:00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.170</td>\n",
       "      <td>4.1385</td>\n",
       "      <td>4.170</td>\n",
       "      <td>16449</td>\n",
       "      <td>[idk, you, know, several, people, hybrids, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-07-24 09:37:00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.180</td>\n",
       "      <td>4.1540</td>\n",
       "      <td>4.175</td>\n",
       "      <td>15605</td>\n",
       "      <td>[thanks, check, out]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-24 09:40:00</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.195</td>\n",
       "      <td>4.1700</td>\n",
       "      <td>4.180</td>\n",
       "      <td>42314</td>\n",
       "      <td>[im, waiting, monday, sell, covered, call, im,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355042</th>\n",
       "      <td>2021-06-30 19:19:00</td>\n",
       "      <td>214.78</td>\n",
       "      <td>214.780</td>\n",
       "      <td>214.7800</td>\n",
       "      <td>214.780</td>\n",
       "      <td>100</td>\n",
       "      <td>[always, possible, like, give, companies, cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355055</th>\n",
       "      <td>2021-06-30 19:40:00</td>\n",
       "      <td>214.80</td>\n",
       "      <td>214.800</td>\n",
       "      <td>214.8000</td>\n",
       "      <td>214.800</td>\n",
       "      <td>176</td>\n",
       "      <td>[business, china, jaded, money, theres, one, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355064</th>\n",
       "      <td>2021-06-30 19:54:00</td>\n",
       "      <td>214.34</td>\n",
       "      <td>214.340</td>\n",
       "      <td>214.3200</td>\n",
       "      <td>214.320</td>\n",
       "      <td>811</td>\n",
       "      <td>[automatically, downvoted, image, alone, then,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355065</th>\n",
       "      <td>2021-06-30 19:55:00</td>\n",
       "      <td>214.15</td>\n",
       "      <td>214.150</td>\n",
       "      <td>214.0000</td>\n",
       "      <td>214.000</td>\n",
       "      <td>1499</td>\n",
       "      <td>[how, get, 12, 000, lost, these, fools, cost, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355068</th>\n",
       "      <td>2021-06-30 19:59:00</td>\n",
       "      <td>214.50</td>\n",
       "      <td>214.500</td>\n",
       "      <td>214.5000</td>\n",
       "      <td>214.500</td>\n",
       "      <td>134</td>\n",
       "      <td>[took, 5, months, squeeze, dividend, announced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    open     high       low    close  volume  \\\n",
       "0        2019-07-24 09:00:00    4.09    4.090    4.0900    4.090     406   \n",
       "11       2019-07-24 09:35:00    4.14    4.150    4.1300    4.150   10116   \n",
       "12       2019-07-24 09:36:00    4.14    4.170    4.1385    4.170   16449   \n",
       "13       2019-07-24 09:37:00    4.17    4.180    4.1540    4.175   15605   \n",
       "14       2019-07-24 09:40:00    4.19    4.195    4.1700    4.180   42314   \n",
       "...                      ...     ...      ...       ...      ...     ...   \n",
       "4355042  2021-06-30 19:19:00  214.78  214.780  214.7800  214.780     100   \n",
       "4355055  2021-06-30 19:40:00  214.80  214.800  214.8000  214.800     176   \n",
       "4355064  2021-06-30 19:54:00  214.34  214.340  214.3200  214.320     811   \n",
       "4355065  2021-06-30 19:55:00  214.15  214.150  214.0000  214.000    1499   \n",
       "4355068  2021-06-30 19:59:00  214.50  214.500  214.5000  214.500     134   \n",
       "\n",
       "                                                     token  \n",
       "0        [index, fund, tracks, performance, stock, mark...  \n",
       "11       [combination, options, made, big, some, crmd, ...  \n",
       "12       [idk, you, know, several, people, hybrids, new...  \n",
       "13                                    [thanks, check, out]  \n",
       "14       [im, waiting, monday, sell, covered, call, im,...  \n",
       "...                                                    ...  \n",
       "4355042  [always, possible, like, give, companies, cred...  \n",
       "4355055  [business, china, jaded, money, theres, one, t...  \n",
       "4355064  [automatically, downvoted, image, alone, then,...  \n",
       "4355065  [how, get, 12, 000, lost, these, fools, cost, ...  \n",
       "4355068  [took, 5, months, squeeze, dividend, announced...  \n",
       "\n",
       "[190326 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Path to file aggregate\n",
    "input_filename = \"./data/processed_reddit_v4_1min.csv.zip\"\n",
    "input_filename = \"./ignore_folder/processed_reddit_v4_1min_amc_stock_comments.pkl\"\n",
    "#output_filename = './ignore_folder/tsvd_model_ready_1min.csv.zip'\n",
    "\n",
    "raw_df = pd.read_pickle(input_filename)\n",
    "#//*** How many columns to pre\n",
    "offset_target = \"1\"\n",
    "\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>token</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-24 09:00:00</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>406</td>\n",
       "      <td>[index, fund, tracks, performance, stock, mark...</td>\n",
       "      <td>index fund tracks performance stock market ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-24 09:31:00</td>\n",
       "      <td>9.846181</td>\n",
       "      <td>9.912903</td>\n",
       "      <td>9.846181</td>\n",
       "      <td>9.912903</td>\n",
       "      <td>23448</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-24 09:32:00</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>9.951029</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>3394</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-24 09:33:00</td>\n",
       "      <td>9.939591</td>\n",
       "      <td>9.998688</td>\n",
       "      <td>9.935302</td>\n",
       "      <td>9.998688</td>\n",
       "      <td>24294</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-24 09:34:00</td>\n",
       "      <td>10.003453</td>\n",
       "      <td>10.017751</td>\n",
       "      <td>9.874776</td>\n",
       "      <td>9.960561</td>\n",
       "      <td>67195</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127120</th>\n",
       "      <td>2021-07-12 19:56:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>41.220000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>10274</td>\n",
       "      <td>_____</td>\n",
       "      <td>im looking viac looks beaten ive also waiting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127121</th>\n",
       "      <td>2021-07-12 19:57:00</td>\n",
       "      <td>41.270000</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>6832</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127122</th>\n",
       "      <td>2021-07-12 19:58:00</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>14056</td>\n",
       "      <td>_____</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127123</th>\n",
       "      <td>2021-07-12 19:59:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.280000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>8974</td>\n",
       "      <td>_____</td>\n",
       "      <td>good you worries it tanking the presentations na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127124</th>\n",
       "      <td>2021-07-12 20:00:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.280000</td>\n",
       "      <td>11989</td>\n",
       "      <td>_____</td>\n",
       "      <td>yes was</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127125 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time       open       high        low      close  \\\n",
       "0       2019-07-24 09:00:00   4.090000   4.090000   4.090000   4.090000   \n",
       "1       2019-07-24 09:31:00   9.846181   9.912903   9.846181   9.912903   \n",
       "2       2019-07-24 09:32:00   9.922435   9.951029   9.922435   9.922435   \n",
       "3       2019-07-24 09:33:00   9.939591   9.998688   9.935302   9.998688   \n",
       "4       2019-07-24 09:34:00  10.003453  10.017751   9.874776   9.960561   \n",
       "...                     ...        ...        ...        ...        ...   \n",
       "127120  2021-07-12 19:56:00  41.250000  41.290000  41.220000  41.290000   \n",
       "127121  2021-07-12 19:57:00  41.270000  41.350000  41.250000  41.330000   \n",
       "127122  2021-07-12 19:58:00  41.330000  41.330000  41.250000  41.250000   \n",
       "127123  2021-07-12 19:59:00  41.250000  41.280000  41.250000  41.250000   \n",
       "127124  2021-07-12 20:00:00  41.250000  41.340000  41.250000  41.280000   \n",
       "\n",
       "        volume                                              token  \\\n",
       "0          406  [index, fund, tracks, performance, stock, mark...   \n",
       "1        23448                                              _____   \n",
       "2         3394                                              _____   \n",
       "3        24294                                              _____   \n",
       "4        67195                                              _____   \n",
       "...        ...                                                ...   \n",
       "127120   10274                                              _____   \n",
       "127121    6832                                              _____   \n",
       "127122   14056                                              _____   \n",
       "127123    8974                                              _____   \n",
       "127124   11989                                              _____   \n",
       "\n",
       "                                                    tfidf  \n",
       "0       index fund tracks performance stock market ind...  \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                   ...  \n",
       "127120  im looking viac looks beaten ive also waiting ...  \n",
       "127121                                                     \n",
       "127122                                                     \n",
       "127123   good you worries it tanking the presentations na  \n",
       "127124                                            yes was  \n",
       "\n",
       "[127125 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df = pd.read_csv(\"./stocks/amc_1min.csv.zip\")\n",
    "stocks_df.sort_values('time', inplace=True, ignore_index=True)\n",
    "tdf = pd.concat([raw_df,stocks_df])\n",
    "tdf.drop_duplicates(subset='time', keep=False,inplace=True)\n",
    "tdf.sort_values('time', inplace=True, ignore_index=True)\n",
    "\n",
    "\n",
    "tdf['tfidf'] = raw_df['token'].apply(lambda x: ' '.join(x))\n",
    "tdf['tfidf'] = tdf['tfidf'].fillna(\" \")\n",
    "tdf['token'] = tdf['token'].replace(np.nan,\"_____\")\n",
    "#del tdf['token']\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words:  93299\n",
      "Words used < 10 times:  80103\n"
     ]
    }
   ],
   "source": [
    "#//*** Build Word Frequencies\n",
    "word_freq = {}\n",
    "\n",
    "for row in tdf['token']:\n",
    "    \n",
    "    if row == \"_____\":\n",
    "        continue\n",
    "    \n",
    "    for word in row:\n",
    "        if word in word_freq.keys():\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "#//*** Sort Dictionary by values. Helpful for exploration\n",
    "#marklist=sorted((value, key) for (key,value) in word_freq.items())\n",
    "#sortdict=dict([(k,v) for v,k in marklist])\n",
    "\n",
    "#//*** Generate a list of stop words\n",
    "filter_words = [\"_____\"]\n",
    "\n",
    "for word, freq in word_freq.items():\n",
    "    if freq < 10:\n",
    "        filter_words.append(word)\n",
    "        \n",
    "print(\"Total Unique Words: \",len(word_freq))     \n",
    "print(\"Words used < 10 times: \",len(filter_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#//************************************************\n",
    "#//*** Clean text body\n",
    "#//************************************************\n",
    "\n",
    "#raw_df['token'] = stoneburner.remove_stop_words(stoneburner.tokenize_series(stoneburner.mr_clean_text(raw_df['body'],{\"remove_empty\":False})))\n",
    "print(\"Done\")\n",
    "\n",
    "#//*** Detokenize the clean column as tfidf\n",
    "tdf['tfidf'] = raw_df['token'].apply(lambda x: ' '.join(x))\n",
    "tdf['tfidf'] = tdf['tfidf'].fillna(\" \")\n",
    "\n",
    "del raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tfidf....\n",
      "Built: 1.43\n",
      "  (0, 20748)\t0.09198608021500064\n",
      "  (0, 28112)\t0.0666530687061076\n",
      "  (0, 7980)\t0.05569028332511497\n",
      "  (0, 32342)\t0.05077676694519475\n",
      "  (0, 4257)\t0.05864966515936296\n",
      "  (0, 39245)\t0.06418612880379934\n",
      "  (0, 35213)\t0.04978620209504083\n",
      "  (0, 39322)\t0.09936612963133123\n",
      "  (0, 30722)\t0.05534818090798994\n",
      "  (0, 26733)\t0.041406572517279076\n",
      "  (0, 36027)\t0.04522560310082354\n",
      "  (0, 25154)\t0.051448545856500855\n",
      "  (0, 28469)\t0.05778449460772951\n",
      "  (0, 43243)\t0.0398230748007572\n",
      "  (0, 24290)\t0.036175554761458846\n",
      "  (0, 16628)\t0.05347026933115812\n",
      "  (0, 14479)\t0.08531992612342328\n",
      "  (0, 36569)\t0.05183828022369823\n",
      "  (0, 13800)\t0.05926027482255534\n",
      "  (0, 8567)\t0.07176472930945256\n",
      "  (0, 8416)\t0.038520928665295\n",
      "  (0, 15075)\t0.04098902664903851\n",
      "  (0, 38754)\t0.04114577443041474\n",
      "  (0, 23040)\t0.05206010014106175\n",
      "  (0, 24809)\t0.04776696179119823\n",
      "  :\t:\n",
      "  (127120, 38621)\t0.1393339423093076\n",
      "  (127120, 24689)\t0.14527330375056338\n",
      "  (127120, 5145)\t0.1279592501031661\n",
      "  (127120, 42080)\t0.1413645178616529\n",
      "  (127120, 36157)\t0.14124732813230617\n",
      "  (127120, 31061)\t0.14596822121426084\n",
      "  (127120, 23044)\t0.13629065254017098\n",
      "  (127120, 18233)\t0.12899417810878056\n",
      "  (127120, 24684)\t0.1383592947522706\n",
      "  (127120, 30549)\t0.18637290781677598\n",
      "  (127120, 41771)\t0.1703344066649757\n",
      "  (127120, 21672)\t0.21702737736749078\n",
      "  (127120, 19096)\t0.2305963529074131\n",
      "  (127120, 34703)\t0.12399941949999782\n",
      "  (127120, 8432)\t0.13622665907233422\n",
      "  (127123, 31007)\t0.5542540092589248\n",
      "  (127123, 38111)\t0.452079114268217\n",
      "  (127123, 42718)\t0.45291925233814884\n",
      "  (127123, 19399)\t0.24680205247499357\n",
      "  (127123, 43211)\t0.20872913182540617\n",
      "  (127123, 22927)\t0.22019757143086635\n",
      "  (127123, 26917)\t0.3144700500520775\n",
      "  (127123, 38592)\t0.17729532453525004\n",
      "  (127124, 43123)\t0.7542204803083281\n",
      "  (127124, 41892)\t0.6566212508619218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Build tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#loop_list.append(tfidf.fit_transform(input_df['tfidf']))\n",
    "tfidf_matrix = []\n",
    "tfidf_list = []\n",
    "tfidf = TfidfVectorizer(stop_words='filter_words')\n",
    "\n",
    "print(\"Starting tfidf....\")\n",
    "start_time = time.time()\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(tdf['tfidf'])\n",
    "\n",
    "\n",
    "print(f\"Built: {round(time.time()-start_time,2)}\")\n",
    "\n",
    "print(tfidf_matrix)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing uneeded columns...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-24 09:00:00</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-24 09:31:00</td>\n",
       "      <td>9.846181</td>\n",
       "      <td>9.912903</td>\n",
       "      <td>9.846181</td>\n",
       "      <td>9.912903</td>\n",
       "      <td>23448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-24 09:32:00</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>9.951029</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>9.922435</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-24 09:33:00</td>\n",
       "      <td>9.939591</td>\n",
       "      <td>9.998688</td>\n",
       "      <td>9.935302</td>\n",
       "      <td>9.998688</td>\n",
       "      <td>24294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-24 09:34:00</td>\n",
       "      <td>10.003453</td>\n",
       "      <td>10.017751</td>\n",
       "      <td>9.874776</td>\n",
       "      <td>9.960561</td>\n",
       "      <td>67195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127120</th>\n",
       "      <td>2021-07-12 19:56:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>41.220000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>10274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127121</th>\n",
       "      <td>2021-07-12 19:57:00</td>\n",
       "      <td>41.270000</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>6832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127122</th>\n",
       "      <td>2021-07-12 19:58:00</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>14056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127123</th>\n",
       "      <td>2021-07-12 19:59:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.280000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>8974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127124</th>\n",
       "      <td>2021-07-12 20:00:00</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>41.280000</td>\n",
       "      <td>11989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time       open       high        low      close  \\\n",
       "0       2019-07-24 09:00:00   4.090000   4.090000   4.090000   4.090000   \n",
       "1       2019-07-24 09:31:00   9.846181   9.912903   9.846181   9.912903   \n",
       "2       2019-07-24 09:32:00   9.922435   9.951029   9.922435   9.922435   \n",
       "3       2019-07-24 09:33:00   9.939591   9.998688   9.935302   9.998688   \n",
       "4       2019-07-24 09:34:00  10.003453  10.017751   9.874776   9.960561   \n",
       "...                     ...        ...        ...        ...        ...   \n",
       "127120  2021-07-12 19:56:00  41.250000  41.290000  41.220000  41.290000   \n",
       "127121  2021-07-12 19:57:00  41.270000  41.350000  41.250000  41.330000   \n",
       "127122  2021-07-12 19:58:00  41.330000  41.330000  41.250000  41.250000   \n",
       "127123  2021-07-12 19:59:00  41.250000  41.280000  41.250000  41.250000   \n",
       "127124  2021-07-12 20:00:00  41.250000  41.340000  41.250000  41.280000   \n",
       "\n",
       "        volume  \n",
       "0          406  \n",
       "1        23448  \n",
       "2         3394  \n",
       "3        24294  \n",
       "4        67195  \n",
       "...        ...  \n",
       "127120   10274  \n",
       "127121    6832  \n",
       "127122   14056  \n",
       "127123    8974  \n",
       "127124   11989  \n",
       "\n",
       "[127125 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Remove Uneeded columns\n",
    "\n",
    "#//*** Separate the time into a separate series\n",
    "print(\"Removing uneeded columns...\")\n",
    "#//*** Remove uneeded columns\n",
    "for col in ['body','token','tfidf']:\n",
    "    if col in tdf.columns:\n",
    "        del tdf[col]\n",
    "\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 41.1 GiB for an array with shape (127125, 43418) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b7f2f2ebf136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 41.1 GiB for an array with shape (127125, 43418) and data type float64"
     ]
    }
   ],
   "source": [
    "tdf = pd.concat([tdf,tfidf_matrix.toarray()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//*** Move this to modeling\n",
    "\n",
    "input_filename = \"./ignore_folder/processed_reddit_v4_60min.pkl.zip\"\n",
    "print(\"Building Target Offset Columns...\")\n",
    "#//*** Build the target variables and intervals of stock prices. This is a single value determined by target)offset\n",
    "\n",
    "#//*** create a list of nan values of x length\n",
    "nan_list = list(np.empty( offset_target )* np.nan )\n",
    "\n",
    "#//*** Create target variable Price which is stocks + x columns in advance\n",
    "#//*** Takes the closing price starting at x and gets the remainder, this generates the offset\n",
    "#//*** nan_list fills the missing x values with nans\n",
    "raw_df[f\"close_{offset_target}\"] = list(raw_df['close'][offset_target:]) + nan_list \n",
    "raw_df    \n",
    "#start_time = time.time()\n",
    "#print(\"Merging...\")\n",
    "##//*** Combine the tfidf sparse array with the stock values\n",
    "#combined_df = pd.concat([raw_df,pd.DataFrame(tfidf_matrix.toarray())], axis=1)\n",
    "#print (f\"Done: {round(time.time()-start_time,2)}s\")\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_filepath = \"./ignore_folder/tsvd_model_ready_60min.csv.zip\"\n",
    "#stock_filepath =  \"./ignore_folder/processed_reddit_v4_60min.pkl.zip\"\n",
    "offset_target = 1\n",
    "\n",
    "start_time = time.time()\n",
    "#print(f\"Reading Stocks: {stock_filepath}\")\n",
    "#stock_df = pd.read_pickle(stock_filepath)\n",
    "\n",
    "print(f\"Building Time Series\")\n",
    "#//*** Peel off Time. Used for graphing\n",
    "#time_series = tdf['time']\n",
    "\n",
    "#print(f\"Cleaning Columns...\")\n",
    "#//*** Remove uneeded columns\n",
    "#for col in ['time','open','high','low','body']:\n",
    "#    if col in tdf.columns:\n",
    "#        del tdf[col]\n",
    "\n",
    "print(\"Building Target Offset Columns...\")\n",
    "#//*** Build the target variables and intervals of stock prices. This is a single value determined by target)offset\n",
    "\n",
    "#//*** create a list of nan values of x length\n",
    "nan_list = list(np.empty( offset_target )* np.nan )\n",
    "\n",
    "#//*** Create target variable Price which is stocks + x columns in advance\n",
    "#//*** Takes the closing price starting at x and gets the remainder, this generates the offset\n",
    "#//*** nan_list fills the missing x values with nans\n",
    "#target = list(stock_df['close'][offset_target:]) + nan_list \n",
    "\n",
    "print(f\"Check Stock Columns are aligned with offset and time\")\n",
    "#//*** Temporarily merge stock_df, time_series, and target series. \n",
    "#//*** Make sure everything is aligning correctly.\n",
    "#temp_df = pd.concat([pd.DataFrame(time_series),pd.DataFrame(target),stock_df],axis=1)\n",
    "#print(temp_df.head(10))\n",
    "#print(temp_df.tail(10))\n",
    "\n",
    "print(f\"Building Combined df for training\")\n",
    "tdf = pd.concat([tdf,tfidf_matrix.toarray()],axis=1)\n",
    "\n",
    "#//*** Delete unused variables to free up memory\n",
    "try:\n",
    "    \n",
    "    del temp_df\n",
    "    del stock_df\n",
    "except:\n",
    "    print()\n",
    "print (f\"Data is training ready: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build TruncatedSVD\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Begin Truncated SVD \")\n",
    "\n",
    "\n",
    "#//*** Set the number of components to 6000. This is generating 98% variance capture\n",
    "#//*** 60min data set took around 25minutes to build\n",
    "tsvd = TruncatedSVD(6000)\n",
    "#tsvd = TruncatedSVD(1000)\n",
    "#tsvd = TruncatedSVD(1000)\n",
    "tsvd_df = pd.DataFrame(tsvd.fit_transform(tfidf_matrix))\n",
    "print(tsvd.explained_variance_ratio_.sum())\n",
    "\n",
    "print (f\"Truncated SVD Done: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "#//*** Write Truncated SVD to disk\n",
    "tsvd_df.to_csv(output_filename, compression='zip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//****1k PCA - .45\n",
    "#//****100 PCA = .13\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "#//*** Write the tsvd object to file, in case it's needed for additional analysis\n",
    "outfile = open('./data/tsvd/truncatedSVD_60min.pkl.zip','wb')\n",
    "pickle.dump(tsvd,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(combined_df)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** set the training columns to use everyting except time\n",
    "predict_col = 'close_1'\n",
    "train_cols = combined_df.columns[1:]\n",
    "train_cols = ['close','volume']\n",
    "\n",
    "x_train = combined_df[train_cols][:1000]\n",
    "y_train = target_df[predict_col][:1000]\n",
    "x_test = combined_df[train_cols][1001:1100]\n",
    "y_test = target_df[predict_col][1001:1100]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "regr = MLPRegressor(max_iter=500).fit(x_train,y_train)\n",
    "#scores = cross_val_score(regr, x_train, y_train, cv=5)\n",
    "#//*** Score the model\n",
    "score = regr.score(x_train, y_train)\n",
    "result = regr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, result)\n",
    "r2 = r2_score(y_test,result)\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Tutorial: https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Begin Train Cols \")\n",
    "train_cols = combined_df.columns[1:]\n",
    "predict_col = 'close_1'\n",
    "print(f\"Begin Slice \")\n",
    "\n",
    "x_train = combined_df[train_cols][:1000]\n",
    "y_train = target_df[predict_col][:1000]\n",
    "x_test = combined_df[train_cols][1001:1013]\n",
    "y_test = target_df[predict_col][1001:1013]\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Begin PCA \")\n",
    "\n",
    "# %%\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "#X = pca.fit_transform( scaler.fit_transform(x_train) ,y_train)\n",
    "x_train = pd.DataFrame(pca.fit_transform( x_train ,y_train))\n",
    "x_test = pd.DataFrame(pca.fit_transform( x_test ,y_train))\n",
    "\n",
    "print(\"Explained Variance Ratio\")\n",
    "for x in range(len(pca.explained_variance_ratio_)):\n",
    "    print(x, pca.explained_variance_ratio_[x])\n",
    "print (f\"PCA Done: {round(time.time()-start_time,2)}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Regressing\")\n",
    "regr = MLPRegressor(max_iter=1000).fit(x_train,y_train)\n",
    "#scores = cross_val_score(regr, x_train, y_train, cv=5)\n",
    "#//*** Score the model\n",
    "score = regr.score(x_train, y_train)\n",
    "result = regr.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, result)\n",
    "r2 = r2_score(y_test,result)\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "print(f\"Complete: {round(time.time()-start_time,2)}\" )\n",
    "\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plot_x = np.arange(len(y_test))\n",
    "ax.plot(plot_x,y_test )\n",
    "ax.scatter(plot_x,result,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(pca.explained_variance_ratio_)):\n",
    "    print(x, pca.explained_variance_ratio_[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
